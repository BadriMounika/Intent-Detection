{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMmLNELrpTY91KlfiQwFUja",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BadriMounika/Intent-Detection/blob/main/intent_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **INTENT** **DETECTION**"
      ],
      "metadata": {
        "id": "EOimCPrNagy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7LQRql4i0hf",
        "outputId": "78a6aaa1-4a84-4ba7-fa92-f93b5ded67ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"huggingface_hub.utils._auth\")"
      ],
      "metadata": {
        "id": "PVRZglqblf-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tokenization**\n",
        " The process of breaking down text into smaller units, or tokens, to make it easier for machines to understand human language. It is the first step in preprocessing text data for machine learning and Natural Language Processing(NLP) tasks."
      ],
      "metadata": {
        "id": "yoaKzBPWkVqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Reading csv file by using pandas\n",
        "import pandas as pd\n",
        "data = pd.read_csv('/content/sofmattress_train.csv')\n",
        "\n",
        "# Loading the BERT tokenizer to prepare text for processing by the BERT\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Tokenizing the sentences(process of splitting text into individual sentences)\n",
        "data['tokenized'] = data['sentence'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))\n",
        "\n",
        "print(data[['sentence', 'tokenized']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESrnp-0Qi_jI",
        "outputId": "60cceeb7-cfe7-40d4-899a-311e1b59c5aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         sentence  \\\n",
            "0                    You guys provide EMI option?   \n",
            "1  Do you offer Zero Percent EMI payment options?   \n",
            "2                                         0% EMI.   \n",
            "3                                             EMI   \n",
            "4                           I want in installment   \n",
            "\n",
            "                                           tokenized  \n",
            "0    [101, 2017, 4364, 3073, 12495, 5724, 1029, 102]  \n",
            "1  [101, 2079, 2017, 3749, 5717, 3867, 12495, 790...  \n",
            "2                [101, 1014, 1003, 12495, 1012, 102]  \n",
            "3                                  [101, 12495, 102]  \n",
            "4                [101, 1045, 2215, 1999, 18932, 102]  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset** **Preparation**\n",
        "1. Encode the categorical labels into numeric format using LabelEncoder.\n",
        "2. Split the data into training (80%) and validation (20%) sets for model evaluation."
      ],
      "metadata": {
        "id": "jRP_-cxrka9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Tokenize with padding and truncation(to make sure that all input sequences have the same length)\n",
        "inputs = tokenizer(list(data['sentence']), max_length=128, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "# Encode labels(to convert categorical variables into numerical values)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "labels = torch.tensor(encoder.fit_transform(data['label']))\n",
        "\n",
        "# Split into training sets and validation sets\n",
        "train_inputs, val_inputs, train_labels, val_labels = train_test_split(\n",
        "    inputs['input_ids'], labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "train_masks, val_masks = train_test_split(inputs['attention_mask'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "-up1hqGulmU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model** **Initialization**\n",
        "1. Loading a pre-trained BERT model (bert-base-uncased) with a classification head for sequence classification tasks.\n",
        "2. The classification head is customized to match the number of unique intent classes in the dataset (num_labels).\n",
        "3. Using pre-trained weights ensures the model starts with a strong understanding of language, improving performance."
      ],
      "metadata": {
        "id": "nH7DmBPwmsIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(encoder.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXj5MNa9mut0",
        "outputId": "18bba8e1-9a11-4e67-bc42-19fc19019487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fine**-**Tuning**\n",
        "1. Optimizer:\n",
        "   - AdamW optimizer is used with a learning rate of 5e-5 for effective fine-tuning of the BERT model.\n",
        "   - It incorporates weight decay to reduce overfitting.\n",
        "2. Training Loop:\n",
        "   - The model is trained in batches, using the DataLoader for efficient iteration.\n",
        "   - Loss is computed for each batch and used to update the model weights via backpropagation.\n",
        "3. Epochs:\n",
        "   - Training is repeated for multiple epochs (3 in this case) to allow the model to converge to better performance."
      ],
      "metadata": {
        "id": "5UjDQZfSm3bm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.optim import AdamW\n",
        "\n",
        "batch_size = 16  # refers to the number of training examples used in one iteration on training process\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5) # Adam optimizer used to train neural networks\n",
        "\n",
        "for epoch in range(3):  # Loop over epochs\n",
        "    model.train()\n",
        "    for batch in train_dataloader:\n",
        "        b_input_ids, b_attention_mask, b_labels = batch\n",
        "        outputs = model(b_input_ids, attention_mask=b_attention_mask, labels=b_labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()"
      ],
      "metadata": {
        "id": "rJE_jH6vm5v-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model** **Evaluation**\n",
        "1. Model Evaluation Mode:\n",
        "   - The model is set to eval() mode to disable gradient computation and ensure consistent results.\n",
        "2. Predictions:\n",
        "   - For each batch in the validation set, logits (raw class scores) are generated.\n",
        "   - The class with the highest score is selected as the predicted label using argmax.\n",
        "3. Metrics:\n",
        "   - Accuracy: Measures the overall proportion of correctly predicted samples.\n",
        "   - Classification Report: Provides detailed metrics (precision, recall, F1-score) for each class to assess the model's performance on different intents.\n",
        "4. Gradient-Free Evaluation:\n",
        "   - Using torch.no_grad() optimizes performance by preventing unnecessary gradient computation."
      ],
      "metadata": {
        "id": "Mihxz_98pYz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report,accuracy_score\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Creating the validation dataloader\n",
        "# This is the missing piece of code causing the error\n",
        "validation_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "validation_dataloader = DataLoader(validation_data, batch_size=batch_size)\n",
        "\n",
        "model.eval()\n",
        "val_predictions = []\n",
        "with torch.no_grad():\n",
        "    for batch in validation_dataloader:\n",
        "        # unpack the batch into three variables\n",
        "        b_input_ids, b_attention_mask, b_labels = batch\n",
        "        logits = model(b_input_ids, attention_mask=b_attention_mask).logits\n",
        "        val_predictions.append(logits.argmax(dim=-1))\n",
        "\n",
        "val_predictions = [item for sublist in val_predictions for item in sublist]\n",
        "\n",
        "# Decode the true labels (actual labels from the validation set)\n",
        "val_true_labels = val_labels.cpu().numpy()\n",
        "\n",
        "# Calculate and print evaluation metrics\n",
        "accuracy = accuracy_score(val_true_labels, val_predictions)\n",
        "report = classification_report(val_true_labels, val_predictions, target_names=encoder.classes_)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECzGDmCkpbFV",
        "outputId": "c1c542d2-daf2-4947-c827-44a1e6a1c270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5152\n",
            "Classification Report:\n",
            "                        precision    recall  f1-score   support\n",
            "\n",
            "100_NIGHT_TRIAL_OFFER       1.00      0.50      0.67         4\n",
            "   ABOUT_SOF_MATTRESS       0.00      0.00      0.00         3\n",
            "         CANCEL_ORDER       0.00      0.00      0.00         2\n",
            "        CHECK_PINCODE       1.00      1.00      1.00         1\n",
            "                  COD       1.00      0.50      0.67         2\n",
            "           COMPARISON       0.00      0.00      0.00         1\n",
            "    DELAY_IN_DELIVERY       0.00      0.00      0.00         2\n",
            "         DISTRIBUTORS       0.88      0.88      0.88         8\n",
            "                  EMI       0.80      0.80      0.80         5\n",
            "        ERGO_FEATURES       0.67      1.00      0.80         4\n",
            "             LEAD_GEN       0.23      0.75      0.35         4\n",
            "        MATTRESS_COST       0.75      1.00      0.86         3\n",
            "               OFFERS       1.00      0.67      0.80         3\n",
            "         ORDER_STATUS       0.09      1.00      0.17         1\n",
            "       ORTHO_FEATURES       0.33      0.33      0.33         3\n",
            "              PILLOWS       0.00      0.00      0.00         3\n",
            "     PRODUCT_VARIANTS       0.40      1.00      0.57         2\n",
            "      RETURN_EXCHANGE       0.50      0.20      0.29         5\n",
            "   SIZE_CUSTOMIZATION       0.00      0.00      0.00         1\n",
            "             WARRANTY       0.00      0.00      0.00         5\n",
            "   WHAT_SIZE_TO_ORDER       0.67      0.50      0.57         4\n",
            "\n",
            "             accuracy                           0.52        66\n",
            "            macro avg       0.44      0.48      0.42        66\n",
            "         weighted avg       0.51      0.52      0.48        66\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Predict** **Function** **for** **User** **Input**\n",
        "1. Tokenization:\n",
        "   - Converts the user-provided query into input IDs and attention masks using the same tokenizer as during training.\n",
        "   - Applies padding and truncation to ensure compatibility with the model's expected input format.\n",
        "2. Model Prediction:\n",
        "   - The model processes the tokenized query in evaluation mode (eval()).\n",
        "   - Logits (raw scores) are computed, and the class with the highest score is selected using argmax.\n",
        "3. Label Decoding:\n",
        "   - The numerical prediction is mapped back to its original string label using the LabelEncoder.\n",
        "4. Interactive Query Input:\n",
        "   - Continuously prompts the user to input queries.\n",
        "   - Displays the predicted intent for each query.\n",
        "   - Exits the loop when the user types \"exit\"."
      ],
      "metadata": {
        "id": "ZAcQm7_kCHCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the Predict Function for User queries\n",
        "def predict_intent(user_input):\n",
        "    inputs = tokenizer(user_input, max_length=128, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
        "        logits = outputs.logits\n",
        "        prediction = logits.argmax(dim=-1).item()  # Get the predicted class\n",
        "    predicted_label = encoder.inverse_transform([prediction])[0]\n",
        "    return predicted_label\n",
        "\n",
        "# Allowing User query and Predicting the Intents\n",
        "while True:\n",
        "    user_query = input(\"Enter your query (or 'exit' to quit): \")\n",
        "    if user_query.lower() == 'exit':\n",
        "        break\n",
        "    predicted_intent = predict_intent(user_query)\n",
        "    print(f\"Predicted Intent: {predicted_intent}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUbmdrv-CIg_",
        "outputId": "a2460180-941f-4e33-a333-4e64b125b629"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your query (or 'exit' to quit): back pain\n",
            "Predicted Intent: ORTHO_FEATURES\n",
            "Enter your query (or 'exit' to quit): i need emi payment?\n",
            "Predicted Intent: EMI\n",
            "Enter your query (or 'exit' to quit): order\n",
            "Predicted Intent: ORDER_STATUS\n",
            "Enter your query (or 'exit' to quit): Do you provide EMI options for this product?\n",
            "Predicted Intent: PRODUCT_VARIANTS\n",
            "Enter your query (or 'exit' to quit): Can I buy this on installments?\n",
            "Predicted Intent: EMI\n",
            "Enter your query (or 'exit' to quit): cash on delivery is available?\n",
            "Predicted Intent: COD\n",
            "Enter your query (or 'exit' to quit): what is the status?\n",
            "Predicted Intent: ORDER_STATUS\n",
            "Enter your query (or 'exit' to quit): exit\n"
          ]
        }
      ]
    }
  ]
}